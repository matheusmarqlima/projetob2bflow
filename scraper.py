import datetime  
import sys       

# --- Verifica√ß√£o de Ferramentas Essenciais ---

try:
    import requests  
    from bs4 import BeautifulSoup  
except ImportError:
    # Se n√£o encontrar as ferramentas, avisamos o usu√°rio 
    print("\n--- Opa! Parece que faltam algumas ferramentas na sua caixa. ---")
    print("Para este script funcionar, precisamos das bibliotecas 'requests' e 'beautifulsoup4'.")
    print("Voc√™ pode instal√°-las facilmente. Abra seu terminal e digite:")
    print("\npip install requests beautifulsoup4\n")
    print("------------------------------------------------------------------")
    sys.exit(1)  # Encerra o programa 

def buscar_noticias_do_g1():
    """
    Navega at√© a p√°gina inicial do G1 e procura pelas √∫ltimas not√≠cias, guardando o t√≠tulo e o link de cada uma.
    Retorna uma lista com as not√≠cias encontradas ou nada (None) se houver um problema.
    """
    url_alvo = "https://g1.globo.com/"
    
    
    # Usar cabe√ßalho de "User-Agent" para que o site pense que √© um navegador comum que est√° acessando a p√°gina.
    cabecalhos = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    print("üöÄ Ol√°! Come√ßando a buscar as √∫ltimas not√≠cias no G1...")
    
    try:
        # Vamos tentar "visitar" a p√°gina. Tempo de 10 segundos para o site responder
        resposta = requests.get(url_alvo, headers=cabecalhos, timeout=10)
        
        # Se a resposta for um c√≥digo de erro, paramos aqui.
        resposta.raise_for_status()

        # Agora, entregamos o HTML da p√°gina para o BeautifulSoup
        pagina_organizada = BeautifulSoup(resposta.content, 'html.parser')

        # Identificamos onde est√£o as manchetes que queremos.
        lista_de_manchetes = pagina_organizada.find_all('a', class_='feed-post-link')

        if not lista_de_manchetes:
            print("‚ö†Ô∏è Puxa, n√£o encontrei nenhuma manchete onde eu costumava procurar.")
            print("Pode ser que a estrutura do site G1 tenha mudado.")
            return None

        noticias_coletadas = []
        for manchete in lista_de_manchetes:
            titulo = manchete.get_text(strip=True)  # Pega o texto limpo do link
            link = manchete['href']                 # Pega o endere√ßo do link
            
            # Guarda a noticia se tiver t√≠tulo e link
            if titulo:
                noticias_coletadas.append({'titulo': titulo, 'link': link})

        print(f"‚úÖ Sucesso! Encontrei {len(noticias_coletadas)} not√≠cias fresquinhas.")
        return noticias_coletadas
        # Em caso de erro do site
    except requests.exceptions.HTTPError as erro:
        print(f"‚ùå Problema de HTTP: {erro}. A p√°gina pode estar fora do ar ou a URL mudou.")
    except requests.exceptions.ConnectionError:
        print("‚ùå Problema de Conex√£o. Parece que voc√™ est√° sem internet. Pode verificar?")
    except requests.exceptions.Timeout:
        print("‚ùå O site demorou demais para responder. Tente novamente mais tarde.")
    except Exception as erro_geral:
        print(f"‚ùå Encontrei um erro inesperado: {erro_geral}")
    
    return None

def salvar_dados(dados_das_noticias):
    """
    Pega a lista de not√≠cias e salva tudo de forma organizada em um arquivo de texto.
    """
    if not dados_das_noticias:
        print("Como n√£o coletei dados, n√£o h√° nada para salvar.")
        return

    nome_do_arquivo = "manchetes_g1.txt"
    data_e_hora = datetime.datetime.now().strftime("%d/%m/%Y √†s %H:%M:%S")

    try:
        with open(nome_do_arquivo, 'w', encoding='utf-8') as arquivo:
            arquivo.write(f"Manchetes do G1\n")
            arquivo.write(f"Coletadas em: {data_e_hora}\n")
            arquivo.write("="*40 + "\n\n")

            for noticia in dados_das_noticias:
                arquivo.write(f"T√≠tulo: {noticia['titulo']}\n")
                arquivo.write(f"Link: {noticia['link']}\n")
                arquivo.write("-"*40 + "\n")

        print(f"üíæ Perfeito! Todas as not√≠cias foram salvas no arquivo '{nome_do_arquivo}'")

    except IOError as e:
        print(f"‚ùå Tive um problema ao tentar criar o arquivo: {e}")

# --- Programa ---

if __name__ == "__main__":
    
    # Inicializa para buscar as not√≠cias do G1
    noticias = buscar_noticias_do_g1()
    
    # Caso retorne noticias, salva elas em um arquivo
    if noticias:
        salvar_dados(noticias)