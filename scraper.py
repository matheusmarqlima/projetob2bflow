import datetime  
import sys       

# --- Verifica√ß√£o de Ferramentas Essenciais ---

try:
    import requests  
    from bs4 import BeautifulSoup  
except ImportError:
    # Se n√£o encontrar as ferramentas, avisamos o usu√°rio 
    print("\n--- Opa! Parece que faltam algumas ferramentas na sua caixa. ---")
    print("Para este script funcionar, precisamos das bibliotecas 'requests' e 'beautifulsoup4'.")
    print("Voc√™ pode instal√°-las facilmente. Abra seu terminal e digite:")
    print("\npip install requests beautifulsoup4\n")
    print("------------------------------------------------------------------")
    sys.exit(1)  # Encerra o programa 

def buscar_noticias_do_g1():
    """
    Navega at√© a p√°gina inicial do G1 e procura pelas √∫ltimas not√≠cias, guardando o t√≠tulo e o link de cada uma.
    Retorna uma lista com as not√≠cias encontradas ou nada (None) se houver um problema.
    """
    url_alvo = "https://g1.globo.com/"
    
    
    # Usar cabe√ßalho de "User-Agent" para que o site pense que √© um navegador comum que est√° acessando a p√°gina.
    cabecalhos = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    print("üöÄ Ol√°! Come√ßando a buscar as √∫ltimas not√≠cias no G1...")
    
    try:
        # Vamos tentar "visitar" a p√°gina. Tempo de 10 segundos para o site responder
        resposta = requests.get(url_alvo, headers=cabecalhos, timeout=10)
        
        # Se a resposta for um c√≥digo de erro, paramos aqui.
        resposta.raise_for_status()

        # Agora, entregamos o HTML da p√°gina para o BeautifulSoup
        pagina_organizada = BeautifulSoup(resposta.content, 'html.parser')

        # Identificamos onde est√£o as manchetes que queremos.
        lista_de_manchetes = pagina_organizada.find_all('a', class_='feed-post-link')

        if not lista_de_manchetes:
            print("‚ö†Ô∏è Puxa, n√£o encontrei nenhuma manchete onde eu costumava procurar.")
            print("Pode ser que a estrutura do site G1 tenha mudado.")
            return None

        noticias_coletadas = []
        for manchete in lista_de_manchetes:
            titulo = manchete.get_text(strip=True)  # Pega o texto limpo do link
            link = manchete['href']                 # Pega o endere√ßo do link
            
            # Guarda a noticia se tiver t√≠tulo e link
            if titulo:
                noticias_coletadas.append({'titulo': titulo, 'link': link})

        print(f"‚úÖ Sucesso! Encontrei {len(noticias_coletadas)} not√≠cias fresquinhas.")
        return noticias_coletadas
        # Em caso de erro do site
    except requests.exceptions.HTTPError as erro:
        print(f"‚ùå Problema de HTTP: {erro}. A p√°gina pode estar fora do ar ou a URL mudou.")
    except requests.exceptions.ConnectionError:
        print("‚ùå Problema de Conex√£o. Parece que voc√™ est√° sem internet. Pode verificar?")
    except requests.exceptions.Timeout:
        print("‚ùå O site demorou demais para responder. Tente novamente mais tarde.")
    except Exception as erro_geral:
        print(f"‚ùå Encontrei um erro inesperado: {erro_geral}")
    
    return None